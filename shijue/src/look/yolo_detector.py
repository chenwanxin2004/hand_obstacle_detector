"""
YOLOç›®æ ‡æ£€æµ‹å™¨ - æ”¯æŒPyTorchå’ŒONNXæ¨¡å‹
"""

import cv2
import numpy as np
from typing import List, Tuple, Optional
import os


class YOLODetector:
    """YOLOç›®æ ‡æ£€æµ‹å™¨ç±» - æ”¯æŒPyTorchå’ŒONNXæ¨¡å‹"""
    
    def __init__(self, model_path: str, conf_threshold: float = 0.5, nms_threshold: float = 0.4):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        
        Args:
            model_path: YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt æˆ– .onnx)
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_threshold: éæå¤§å€¼æŠ‘åˆ¶é˜ˆå€¼
        """
        self.model_path = model_path
        self.conf_threshold = conf_threshold
        self.nms_threshold = nms_threshold
        self.model_type = None
        self.net = None
        
        # æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶åŠ è½½
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
            return
        
        file_ext = os.path.splitext(self.model_path)[1].lower()
        
        try:
            if file_ext == '.pt':
                # PyTorchæ¨¡å‹
                self._load_pytorch_model()
            elif file_ext == '.onnx':
                # ONNXæ¨¡å‹
                self._load_onnx_model()
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {file_ext}")
                print("æ”¯æŒçš„æ ¼å¼: .pt (PyTorch), .onnx (ONNX)")
                print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
    
    def _load_pytorch_model(self):
        """åŠ è½½PyTorchæ¨¡å‹"""
        try:
            import torch
            from ultralytics import YOLO
            
            print(f"ğŸ”„ æ­£åœ¨åŠ è½½PyTorchæ¨¡å‹: {self.model_path}")
            self.model = YOLO(self.model_path)
            self.model_type = 'pytorch'
            print(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            
        except ImportError:
            print("âŒ ç¼ºå°‘PyTorchä¾èµ–ï¼Œè¯·å®‰è£…: pip install torch ultralytics")
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
        except Exception as e:
            print(f"âŒ PyTorchæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
    
    def _load_onnx_model(self):
        """åŠ è½½ONNXæ¨¡å‹"""
        try:
            print(f"ğŸ”„ æ­£åœ¨åŠ è½½ONNXæ¨¡å‹: {self.model_path}")
            self.net = cv2.dnn.readNetFromONNX(self.model_path)
            self.model_type = 'onnx'
            print(f"âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            
        except Exception as e:
            print(f"âŒ ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹å™¨...")
    
    def detect(self, image: np.ndarray) -> List[Tuple[int, int, int, int, float, int]]:
        """
        æ‰§è¡Œç›®æ ‡æ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (x1, y1, x2, y2, confidence, class_id)
        """
        if self.model_type == 'pytorch':
            return self._detect_pytorch(image)
        elif self.model_type == 'onnx':
            return self._detect_onnx(image)
        else:
            # æ¨¡æ‹Ÿæ£€æµ‹å™¨
            return self._mock_detection(image)
    
    def _detect_pytorch(self, image: np.ndarray) -> List[Tuple[int, int, int, int, float, int]]:
        """ä½¿ç”¨PyTorchæ¨¡å‹è¿›è¡Œæ£€æµ‹"""
        try:
            # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ¨ç†
            results = self.model(image, verbose=False)
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        if confidence > self.conf_threshold:
                            detections.append((
                                int(x1), int(y1), int(x2), int(y2), 
                                confidence, class_id
                            ))
            
            return detections
            
        except Exception as e:
            print(f"âš ï¸ PyTorchæ£€æµ‹å¤±è´¥: {e}")
            return self._mock_detection(image)
    
    def _detect_onnx(self, image: np.ndarray) -> List[Tuple[int, int, int, int, float, int]]:
        """ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œæ£€æµ‹"""
        try:
            # é¢„å¤„ç†å›¾åƒ
            blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)
            
            # å‰å‘æ¨ç†
            self.net.setInput(blob)
            outputs = self.net.forward()
            
            # åå¤„ç†æ£€æµ‹ç»“æœ
            return self._process_onnx_outputs(outputs, image.shape)
            
        except Exception as e:
            print(f"âš ï¸ ONNXæ£€æµ‹å¤±è´¥: {e}")
            return self._mock_detection(image)
    
    def _process_onnx_outputs(self, outputs: np.ndarray, image_shape: Tuple[int, int, int]) -> List[Tuple[int, int, int, int, float, int]]:
        """å¤„ç†ONNXæ¨¡å‹è¾“å‡º"""
        detections = []
        height, width = image_shape[:2]
        
        # å¤„ç†YOLOv8è¾“å‡ºæ ¼å¼
        for detection in outputs[0]:
            confidence = float(detection[4])
            
            if confidence > self.conf_threshold:
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                x_center = detection[0] * width
                y_center = detection[1] * height
                w = detection[2] * width
                h = detection[3] * height
                
                # è½¬æ¢ä¸ºå·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
                x1 = int(x_center - w/2)
                y1 = int(y_center - h/2)
                x2 = int(x_center + w/2)
                y2 = int(y_center + h/2)
                
                # è·å–ç±»åˆ«ID
                class_id = int(detection[5])
                
                detections.append((x1, y1, x2, y2, confidence, class_id))
        
        return detections
    
    def _mock_detection(self, image: np.ndarray) -> List[Tuple[int, int, int, int, float, int]]:
        """
        æ¨¡æ‹Ÿæ£€æµ‹å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼Œå½“æ¨¡å‹æœªåŠ è½½æ—¶ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            æ¨¡æ‹Ÿçš„æ£€æµ‹ç»“æœ
        """
        height, width = image.shape[:2]
        
        # åœ¨å›¾åƒä¸­å¿ƒåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ£€æµ‹æ¡†
        center_x, center_y = width // 2, height // 2
        box_size = min(width, height) // 4
        
        x1 = center_x - box_size // 2
        y1 = center_y - box_size // 2
        x2 = center_x + box_size // 2
        y2 = center_y + box_size // 2
        
        return [(x1, y1, x2, y2, 0.95, 0)]  # æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
    
    def get_model_info(self) -> str:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if self.model_type == 'pytorch':
            return f"PyTorchæ¨¡å‹: {os.path.basename(self.model_path)}"
        elif self.model_type == 'onnx':
            return f"ONNXæ¨¡å‹: {os.path.basename(self.model_path)}"
        else:
            return "æ¨¡æ‹Ÿæ£€æµ‹å™¨"
